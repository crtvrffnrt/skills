---
name: pentest-hacktricks-finder
description: Search and retrieve pentesting, red teaming, and security research information from the HackTricks wiki (book.hacktricks.wiki). Use for payloads, methodologies, bypasses, and edge-case behaviors across web, network, cloud, and application security topics.
version: 2.1
---

# HackTricks Search Skill

## Purpose

Use this skill to reliably discover and extract the most relevant HackTricks pages for a given technique, vulnerability class, bypass, or exploitation workflow, then pull the exact sections needed (payloads, prerequisites, caveats, and defensive notes).

HackTricks can be inconsistently indexed across search engines. This skill therefore defines two search backends:

1. Primary: Exa-based web search with strict site scoping.
2. Secondary: DuckDuckGo dorks with strict site scoping and noise reduction.

Use the secondary backend when:
- Exa results are sparse or irrelevant.
- You need very tight matching by title/path/keyword.
- You want reproducible dork sets for common vuln classes.

## Scope Guardrails

Only target content under:

```text
https://book.hacktricks.wiki/en/
```

Avoid unrelated mirrors, translations, or cached copies unless explicitly requested.

## Inputs

- Topic: a short phrase describing the target, example: “DOM XSS bypass”, “XXE parameter entities”, “CSRF SameSite bypass”.
- Optional: vuln class (XSS, XXE, CSRF, SSRF, SSTI, IDOR, Smuggling, Deserialization).
- Optional: constraints (framework, language, cloud provider, WAF, browser).

## Workflow

1. Search (Exa first, DDG fallback, or use Exa to search in duckduckgo
2. Verify the URL matches the intended subtree and topic. Not exact match needed but same TTP (Tactics, Techniques and Procedures)
3. Fetch the page content.
4. Extract the relevant section(s):
   - Payloads and variants
   - Preconditions / limitations
   - Bypass techniques
   - Detection / hardening notes (when needed)
5. Return:
   - The selected URLs
   - The extracted payloads / steps
   - Any prerequisites and constraints

## Backend A: Exa Search (Primary)

### Generic pattern

```javascript
web_search_exa({
  query: "site:book.hacktricks.wiki/en <topic>",
  include: ["https://book.hacktricks.wiki/en/*"]
})
```

### Tighten results (recommended)

```javascript
web_search_exa({
  query: "site:book.hacktricks.wiki/en (<high-entropy keywords>) (<bypass|payload|trick|technique>)",
  include: ["https://book.hacktricks.wiki/en/*"]
})
```

Notes:
- Prefer 1–3 high-entropy tokens over long keyword chains (page slugs, function names, CVE IDs, unique headings).
- If Exa returns index pages, pivot to deeper subpages under the same directory.

## Backend B: DuckDuckGo Dorking (Secondary)

DuckDuckGo query semantics are not identical to Google “dorking”. Adjust how you construct queries:

- Do not assume implicit AND across space-separated terms. Use high-entropy anchors (slugs, quoted phrases, intitle/inurl).
- DuckDuckGo can relax constraints and show “related results” if an operator-heavy query yields few/no hits. When this happens, tighten with slugs/quotes rather than adding generic keywords.
- `+term` is a relevance boost, not a strict requirement.
- Prefer `site:` + `inurl:` / `intitle:` + quoted phrase + negative filters over boolean-style chains.

Supported operators you should rely on:
- Quotes for exact phrases
- Exclusion `-term` and `-site:example.com`
- `site:`, `inurl:`, `intitle:`, `filetype:` (limited set)

### Baseline template (DDG-correct)

```text
site:book.hacktricks.wiki inurl:/en/ <high-entropy tokens> -inurl:/print -inurl:/index -inurl:/tags
```

### High-signal, ready-to-run dork sets (5)

Dork 1: XSS subtree by slug anchor (page discovery)

```text
site:book.hacktricks.wiki inurl:/en/pentesting-web/ inurl:xss-cross-site-scripting -inurl:/print -inurl:/index -inurl:/tags
```

Dork 2: XSS subpages by title within the XSS subtree

```text
site:book.hacktricks.wiki inurl:/en/pentesting-web/xss-cross-site-scripting/ intitle:XSS -inurl:/print -inurl:/index
```

Dork 3: XXE main page + nearby content by slug anchor

```text
site:book.hacktricks.wiki inurl:/en/pentesting-web/ inurl:xxe-xee-xml-external-entity -inurl:/print -inurl:/index
```

Dork 4: CSRF main page + nearby content by slug anchor

```text
site:book.hacktricks.wiki inurl:/en/pentesting-web/ inurl:csrf-cross-site-request-forgery -inurl:/print -inurl:/index
```

Dork 5: Technique pivot using a quoted phrase (tight matching)

```text
site:book.hacktricks.wiki inurl:/en/ "SameSite=None" inurl:pentesting-web -inurl:/print -inurl:/index
```

## Targeted Search Playbooks (Slug-first)

These playbooks are designed to work well with DuckDuckGo by anchoring on stable HackTricks slugs and directories.

### XSS playbook

```text
site:book.hacktricks.wiki inurl:/en/pentesting-web/xss-cross-site-scripting/ (csp OR waf OR bypass OR payload) -inurl:/print -inurl:/index
```

### XXE playbook

```text
site:book.hacktricks.wiki inurl:/en/pentesting-web/ inurl:xxe-xee-xml-external-entity (DTD OR "parameter entity" OR payload) -inurl:/print -inurl:/index
```

### CSRF playbook

```text
site:book.hacktricks.wiki inurl:/en/pentesting-web/ inurl:csrf-cross-site-request-forgery ("SameSite" OR token OR origin OR referer) -inurl:/print -inurl:/index
```

### SSRF playbook

```text
site:book.hacktricks.wiki inurl:/en/pentesting-web/ssrf-server-side-request-forgery/ (metadata OR cloud OR redirect OR bypass) -inurl:/print -inurl:/index
```

### SSTI playbook

```text
site:book.hacktricks.wiki inurl:/en/pentesting-web/ssti-server-side-template-injection/ (payload OR bypass OR sandbox) -inurl:/print -inurl:/index
```

### IDOR playbook

```text
site:book.hacktricks.wiki inurl:/en/pentesting-web/ (idor OR "insecure direct object reference" OR "broken access control") -inurl:/print -inurl:/index
```

## Verification Checklist (Before Fetch)

- URL starts with the /en/ subtree.
- The slug matches the intended vuln class (or at least the intended technique).
- The page is not an index-only aggregator when you need payload detail.
- If DuckDuckGo returns “related results”, reduce generic terms and increase specificity (slug + quoted phrase).

## Fetch and Extraction

After selecting URLs, fetch with your normal content retrieval function and extract:

- Section headers that contain payloads, bypasses, PoCs
- Any prerequisites (versions, libraries, browser constraints)
- Any “gotchas” (encoding, parsing differences, WAF behaviors)

Return results in a minimal structure:

```json
{
  "topic": "<topic>",
  "selected_urls": [
    "https://book.hacktricks.wiki/en/..."
  ],
  "extracted": [
    {
      "url": "https://book.hacktricks.wiki/en/...",
      "sections": ["<header 1>", "<header 2>"],
      "payloads_or_steps": ["<payload/step 1>", "<payload/step 2>"],
      "constraints": ["<constraint 1>", "<constraint 2>"]
    }
  ]
}
```

## Notes for Pentesters

- Prefer subtree-restricted searches first (example: xss-cross-site-scripting, ssrf-server-side-request-forgery).
- Prefer 1–3 high-entropy anchors (slug/dir/quoted phrase) over long keyword chains.
- When you find a strong index page, pivot to deeper subpages under the same directory for payload detail.
